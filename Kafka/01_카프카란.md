# 카프카란?

## 1. 카프카 토픽

### 토픽

토픽은 카프카 클러스터 내부의 `데이터 스트림`을 의미한다.

- 메시지 시퀀스를 데이터 스트림이라고 한다.
- 즉, 카프카는 데이터 스트리밍 플랫폼
- 토픽은 이름을 통해 식별한다.

토픽은 여러 형태로 존재할 수 있다.

- 로그, 구매 이력, 트윗, 위치좌표 등...

DB 테이블과 유사하지만 규약과 데이터 검증이 없다.

- 모든 종류의 메시지 포맷을 지원한다. (JSON, CSV, 텍스트 ...)
- 토픽에 질의할 수 없다.
    - 카프카 프로듀서를 통해 카프카 토픽에 데이터를 추가할 수 있다.
    - 카프카 컨슈머를 통해서 토픽의 데이터를 읽는다.

### 파티션과 오프셋

각 토픽은 파티션으로 분할할 수 있다.

- 토픽으로 전송된 메시지는 파티션 내부에서 순서가 정해진다.
- 파티션 내부의 데이터는 증가하는 ID 값을 가지며 이를 `카프카 파티션 오프셋`이라고 한다.
- 카프카 파티션 불변하므로 데이터가 기록되면 변경할 수 없다.
- 파티션에 기록된 데이터는 제한 시간이 지나면 삭제된다. (기본 값은 1주일)

## 2. 프로듀서

### 프로듀서의 역할

토픽-파티션에 데이터를 담기 위해선 프로듀서가 필요하다.

- 기록될 파티션을 결정하는 것은 프로듀서다.
- 카프카 서버에서 파티션에 장애가 발생할 경우 프로듀서가 그 상태와 복구 방안을 확인한다.

### 메커니즘

카프카는 스케일링을 한다.

- 각 파티션은 단일/복수의 프로듀서로부터 메시지를 받음.
- 이 경우 로드밸런싱이 발생

프로듀서는 메시지 키를 가짐 (선택사항)

- 키가 Null이면 라운드로빈
- 동일한 키를 가지는 모든 메시지는 같은 파티션에 저장된다.
- 따라서, 키를 지정할때 특정 필드에 대한 메시지 순서를 설정해야 한다.

### Message Serializer

메시지를 구성할 때는 바이트가 아닌 객체이다. 

- 프로듀서가 입력값으로 직렬화 된 바이트를 받는다.
- 출력 바이트는 컨슈머로 보낸다.
- 따라서, 데이터 송-수신을 위해 직렬화가 필요하다. (바이트로 변환)
- 직렬화는 키-값에만 사용된다.

### 키 해싱 전략

카프카 파티션은 메시지를 받아서 파티션을 지정한다.

이때, 키 해싱 알고리즘인 `murmur2` 알고리즘을 통해서 파티션 결정한다.

- https://en.wikipedia.org/wiki/MurmurHash

## 3. 컨슈머

### 컨슈머

토픽에서 데이터를 읽기 위해서 필요하다.

컨슈머는 Pull 기반 모델이다. (데이터 요청에 대한 응답)

- 메시지를 컨슈머가 (Subscriber)가 읽어온다.
- https://stackoverflow.com/questions/39586635/why-is-kafka-pull-based-instead-of-push-based
    - 요약) 토픽에서 데이터를 추출하는 여러 컨슈머가 있고 각 컨슈머의 처리 속도는 다르다.
    - 카프카 컨슈머의 스루풋 문제

컨슈머는 어떤 브로커(카프카 서버)에서 데이터를 읽을지 알고 있다.

- 컨슈머가 여러 파티션을 읽을 경우 파티션 간의 순서는 보장되지 않는다.
- 컨슈머는 바이트를 객체나 데이터로 변환한다. (메세지 타입을 알아야 한다.)
- 컨슈머는 키-값 형식을 안다면 역직렬화를 수행할 수 있다.

### 컨슈머 그룹

앱 내부의 많은 컨슈머가 스케일링을 하려는 상황을 가정하자. 

컨슈머가 그룹 형태로 데이터를 읽고 이 것을 컨슈머 그룹이라고 한다.

- `Partition < Consumer` : 남은 컨슈머 비활성화

토픽에 대해 컨슈머 그룹 역시 다수가 될 수 있다.

- 그 이유는 같은 토픽-파티션을 읽더라도 여러 다른 서비스에 이용될 수 있기 때문이다.

각각의 컨슈머에게 그룹을 지정하기 위해서 `groud.id`를 이용한다.

- 그룹 안에서는 컨슈머 오프셋을 정의할 수 있다.
- 카프카는 읽고 있는 오프셋을 저장한다.
- 오프셋은 카프카 토픽 내에 `__consumer_offsets`라는 이름으로 존재한다.

### 오프셋 커밋

오프셋이 커밋되면 해당 오프셋부터 컨슈머가 읽게 된다.

- 커밋 후 브로커에게 어디까지 성공적으로 읽었는지 알려줄 수 있게 된다.
- 컨슈머에 장애가 발생하고 복구되면 다시 읽을 오프셋을 알아야한다.

자바 컨슈머는 자동으로 커밋한다. (최소 한번)

수동 커밋을 선택할 경우 3가지 방법론이 있다. (DB 트랜잭션 커밋과 유사)

- `최소 한번(At least once)` : 메시지가 처리된 직후 오프셋 커밋. 이 경우 메세지 처리를 반복할 수 있게 되는데 여기서 멱등성을 보장하는지 확인해야 한다.
- `최대 한번(At most once)` : 컨슈머가 메세지를 받자마자 오프셋 커밋. 처리가 잘못되면 메세지를 잃음 (처리 전이기때문)
- `정확히 한번(Exatly once)` : 메세지를 딱 한 번 처리.
    - kafka2kafka 워크플로우 : 트랜잭션 API를 사용할 수 있다. 카프카 스트림 API를 활용한다면 쉽다.
    - kafka2external 워크플로우 :  멱등 컨슈머를 활용해야 한다.

## 4. 브로커

### 브로커

카프카 클러스터는 여러 브로커(서버)로 구성된다.

- 브로커는 정수 ID로 식별한다.
- 브로커는 특정 토픽 파티션만 담긴다.
- 특정 카프카 브로커에 연결하면 카프카 클러스터에 자동으로 연결된다.
    - 즉, 클러스터의 모든 브로커에 연결할 필요 없이 필요한 브로커에만 연결하면 된다.
    

### 클라이언트-브로커

여러 브로커가 있고 각 브로커는 분산된 토픽, 파티션을 가진다고 가정하자.

- 브로커1 : 토픽A-파티션1, 토픽B-파티션1
- 브로커2: 토픽A-파티션3, 토픽V-파티션2
- 브로커3: 토픽A-파티션2

브로커가 모든 데이터를 가지지는 않는다.

- 카프카 클라이언트가 브로커 1에 연결 요청을 보내면 브로커1은 클라이언트에 모든 브로커 리스트를 보낸다.
    - 어떤 브로커가 어떤 파티션을 갖는지 등의 정보가 포함된다.
    - 데이터 pub-sub을 위해 필요한 브로커에 연결한다.

### 카프카 토픽 복제

카브카 브로커에 사본을 두어 장애에 대응하는 개념이다.

복제 계수를 통해 사본의 수를 관리한다.

- 배포 환경에서 복제 계수를 2~3 정도로 설정한다.


파티션 리더

- 언제나 브로커 내 파티션 1개만 리더가 될 수 있다.
- 레플리카는 ISR(in sync replica)라고 한다.
- 기본값의 경우
    - 프로듀서는 파티션의 리더를 가진 브로커에만 기록한다.
    - 컨슈머는 리더를 가진 브로커에만 데이터를 요청한다.
- 리더가 다운되면 레플리카가 리더가 된다.

Replica Fetching (v2.4+)

- 컨슈머가 가장 가까운 레플리카에서 데이터를 읽는 것
- 이는 레이턴시를 개선하고 네트워크 비용을 감소시킨다.

### 데이터 쓰기 확인

프로듀서는 데이터 쓰기가 정상적으로 완료되었다는 것을 브로커부터 알 수 있다.

- `acks=0` : 프로듀서가 확인을 기다리지 않음. (데이터 유실 허용)
- `acks=1` : 프로듀서가 파티션의 리더를 기다림 (데이터 유실을 제한)
- `acks=all` : 리더, 모든 레플리카에 리더가 쓰기를 확인요청함 (데이터 유실을 허용하지 않음)

## Appendix.
[Deview 2023 - 네이버 스케일로 카프카 이용하기](https://deview.kr/2023/sessions/577)
